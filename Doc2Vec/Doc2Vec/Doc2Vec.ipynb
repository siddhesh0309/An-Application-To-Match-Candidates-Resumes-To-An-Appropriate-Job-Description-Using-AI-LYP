{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "264e4883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gensim\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bddbd43",
   "metadata": {},
   "source": [
    "# Init corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "be9669be",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_doc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "533d3e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_train_corpus = []\n",
    "test_corpus = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61388bd2",
   "metadata": {},
   "source": [
    "# Get Resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b09a3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "projectDir = 'D://pythonProject/Internship/Resume Screening/data/'\n",
    "cleanResumeDir = projectDir+'new_preprocessed_txt_data/'\n",
    "\n",
    "arr_dir = ['3D', 'Admin - CTV', 'AI', 'BLOCKCHAIN', 'C#', 'DEVOPS', 'HELPDESK', 'JAVA', 'KAGGLE', 'PHP', 'PYTHON', 'REACTJS',\n",
    "          'RUBY', 'TESTER', 'UNITY', 'INTERN/OK', 'INTERN/PNV', 'INTERN/SUMMER INTERN 2021',\n",
    "           'INTERN/SUMMER INTERN 2021/Intern Blockchain', 'NODEJS/I.2021', 'NODEJS/II.2021']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "566ac1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir in arr_dir:\n",
    "    new_dir = cleanResumeDir+dir\n",
    "    os.chdir(new_dir)\n",
    "    for clean_resume in os.listdir(new_dir):\n",
    "        if clean_resume == \"Intern Blockchain\":\n",
    "            continue\n",
    "        file = open(str(clean_resume), 'r')\n",
    "        resume = file.read()\n",
    "        all_doc.append(resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0838a8ab",
   "metadata": {},
   "source": [
    "# Get JDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7096688e",
   "metadata": {},
   "outputs": [],
   "source": [
    "projectDir = 'D://pythonProject/Internship/Resume Screening/data/'\n",
    "clean_jd_dir = projectDir+'new_preprocessed_txt_JD/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1e6792bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(clean_jd_dir)\n",
    "for clean_jd in os.listdir(clean_jd_dir):\n",
    "    file = open(str(clean_jd), 'r')\n",
    "    jd = file.read()\n",
    "    all_doc.append(jd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0943df14",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "31a1b52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_doc = len(all_doc)\n",
    "random.shuffle(all_doc)\n",
    "i = 0\n",
    "for i in range(len_doc):\n",
    "    if i <= (len_doc*0.95):\n",
    "        tagged_train_corpus.append(gensim.models.doc2vec.TaggedDocument(all_doc[i].split(), [i]))\n",
    "    else:\n",
    "        test_corpus.append(all_doc[i].split())\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "49910e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 1\n"
     ]
    }
   ],
   "source": [
    "print(len(tagged_train_corpus), len(test_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b5b4c8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['html', 'css', 'javascript', 'mvc', 'cd'], tags=[1])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_train_corpus[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "101bd4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[]]\n"
     ]
    }
   ],
   "source": [
    "print(test_corpus[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c33f1fa",
   "metadata": {},
   "source": [
    "# Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "71553961",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=100, min_count=2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5e9c655e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(tagged_train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d8e69e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 'nodejs' appeared 21 times in the training corpus.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Word 'nodejs' appeared {model.wv.get_vecattr('nodejs', 'count')} times in the training corpus.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53542601",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "09a17fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this if you have loaded the last model\n",
    "model = model_resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "22ac9257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jd: 1000 epochs\n",
    "# resume: 1000 epochs\n",
    "model.train(tagged_train_corpus, total_examples=model.corpus_count, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "63620e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = []\n",
    "second_ranks = []\n",
    "for doc_id in range(len(tagged_train_corpus)):\n",
    "    inferred_vector = model.infer_vector(tagged_train_corpus[doc_id].words)\n",
    "    sims = model.dv.most_similar([inferred_vector], topn=len(model.dv))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "    second_ranks.append(sims[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "20181159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 31, 1: 2, 34: 1, 33: 1})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "counter = collections.Counter(ranks)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "774717b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document (34): «»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dm/m,d100,n5,w5,mc2,s0.001,t3):\n",
      "\n",
      "MOST (25, 0.23486721515655518): «node js php»\n",
      "\n",
      "SECOND-MOST (16, 0.21202312409877777): «framework framework postgresql js docker»\n",
      "\n",
      "MEDIAN (10, 0.06275653839111328): «php php php php laravel framework mvc php framework laravel cakephp mysql mongodb restful api nodejs reactjs vuejs cd docker»\n",
      "\n",
      "LEAST (11, -0.18660326302051544): «reactjs vuejs vuejs html css javascript reactjs ux reactjs vuejs html css javascript es5 framework sass angular nodejs mongodb mysql ux restful api»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Document ({}): «{}»\\n'.format(doc_id, ' '.join(tagged_train_corpus[doc_id].words)))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('SECOND-MOST', 1), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(tagged_train_corpus[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "36f74e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Document (2): «blockchain php nodejs reactjs php nodejs reactjs chance blockchain php nodejs reactjs blockchain deep php javascript blockchain php nodejs reactjs blockchain»\n",
      "\n",
      "Similar Document (6, 0.8194918036460876): «php»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pick a random document from the corpus and infer a vector from the model\n",
    "doc_id = random.randint(0, len(tagged_train_corpus) - 1)\n",
    "\n",
    "# Compare and print the second-most-similar document\n",
    "print('Train Document ({}): «{}»\\n'.format(doc_id, ' '.join(tagged_train_corpus[doc_id].words)))\n",
    "sim_id = second_ranks[doc_id]\n",
    "print('Similar Document {}: «{}»\\n'.format(sim_id, ' '.join(tagged_train_corpus[sim_id[0]].words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cadc3b",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ee0ff285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Document (0): «»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dm/m,d100,n5,w5,mc2,s0.001,t3):\n",
      "\n",
      "MOST (11, 0.20748168230056763): «reactjs vuejs vuejs html css javascript reactjs ux reactjs vuejs html css javascript es5 framework sass angular nodejs mongodb mysql ux restful api»\n",
      "\n",
      "MEDIAN (15, 0.010806656442582607): «nodejs php javascript entrepreneurial»\n",
      "\n",
      "LEAST (30, -0.2499840408563614): «framework framework postgresql react docker»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pick a random document from the test corpus and infer a vector from the model\n",
    "doc_id = random.randint(0, len(test_corpus) - 1)\n",
    "inferred_vector = model.infer_vector(test_corpus[doc_id])\n",
    "sims = model.dv.most_similar([inferred_vector], topn=len(model.dv))\n",
    "\n",
    "# Compare and print the most/median/least similar documents from the train corpus\n",
    "print('Test Document ({}): «{}»\\n'.format(doc_id, ' '.join(test_corpus[doc_id])))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(tagged_train_corpus[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191bb422",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40480ebd",
   "metadata": {},
   "source": [
    "## Save the model for JD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ebc46e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelDir = 'D://pythonProject/Internship/Resume Screening/Entity Extraction/Doc2Vec/model'\n",
    "os.chdir(modelDir)\n",
    "#SAVE THE MODEL\n",
    "model_name = \"model_jd_doc2vec_new\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5ba6e0",
   "metadata": {},
   "source": [
    "## Save the model for resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d2fe78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelDir = 'D://pythonProject/Internship/Resume Screening/Entity Extraction/Doc2Vec/model'\n",
    "os.chdir(modelDir)\n",
    "model_name = \"model_resume_doc2vec_new\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183832d5",
   "metadata": {},
   "source": [
    "# Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e505b438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7440781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_train = json.dumps(tagged_train_corpus)\n",
    "json_test = json.dumps(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2a48525",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonFile = open(\"D://pythonProject/Internship/Resume Screening/Entity Extraction/Doc2Vec/data/new_resume_train_data.json\", \"w+\")\n",
    "jsonFile.write(json_train)\n",
    "jsonFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ce2311d",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonFile = open(\"D://pythonProject/Internship/Resume Screening/Entity Extraction/Doc2Vec/data/new_resume_test_data.json\", \"w+\")\n",
    "jsonFile.write(json_test)\n",
    "jsonFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "27f8dc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonFile = open(\"D://pythonProject/Internship/Resume Screening/Entity Extraction/Doc2Vec/data/new_jd_train_data.json\", \"w+\")\n",
    "jsonFile.write(json_train)\n",
    "jsonFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "701c265e",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonFile = open(\"D://pythonProject/Internship/Resume Screening/Entity Extraction/Doc2Vec/data/new_jd_test_data.json\", \"w+\")\n",
    "jsonFile.write(json_test)\n",
    "jsonFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d53da8",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c7d92a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# run this to get the last dataset\n",
    "file = open(\"D://pythonProject/Internship/Resume Screening/Entity Extraction/Doc2Vec/data/new_jd_train_data.json\", 'r')\n",
    "tagged_train_corpus = json.loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "af3e7270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tagged_train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "77892c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tagged_train_corpus)):\n",
    "    tagged_train_corpus[i] = gensim.models.doc2vec.TaggedDocument(tagged_train_corpus[i][0], tagged_train_corpus[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "81e0be0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['postgresql', 'mysql', 'mongodb', 'cloudformation', 'docker', 'container'], tags=[0])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_train_corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c0d642",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18a2f1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os\n",
    "\n",
    "projectDir = 'D://pythonProject/Internship/Resume Screening/'\n",
    "modelDir = projectDir + 'Entity Extraction/Doc2Vec/model'\n",
    "os.chdir(modelDir)\n",
    "\n",
    "model_jd = gensim.models.Doc2Vec.load('model_jd_doc2vec_new')\n",
    "model_resume = gensim.models.Doc2Vec.load('model_resume_doc2vec_new')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d91ca8d",
   "metadata": {},
   "source": [
    "# Get vectors for new input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7b8455e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bap', 'software', 'co', 'ltd', '10f', '81', 'quang', 'trung', 'st', 'hai', 'chau', 'dist', 'da', 'nang', 'city', 'vietnam', 'website', 'https://bap-software.net/en/', 'ai', 'engineer', 'job', 'overview', 'bap', 'software', 'co', 'ltd', 'software', 'outsourcing', 'provider', 'one', 'subsidiaries', 'bap', 'group', 'always', 'aim', 'bring', 'innovation', 'products', 'customers', 'well', 'looking', 'talented', 'ai', 'engineer', 'da', 'nang', 'excited', 'part', 'winning', 'team', 'bap', 'great', 'place', 'grow', 'career', 'key', 'responsibilities', 'join', 'ai', 'team', 'ai', 'engineer', 'role', 'develop', 'projects', 'applying', 'ai', 'technology', 'design', 'implement', 'ai', 'technology', 'new', 'project', 'research', 'develop', 'ai', 'deep', 'learning', 'machine', 'learning', 'applications', 'assignments', 'key', 'skills', 'qualifications', 'models', '2', '+', 'years', 'experience', 'implementing', 'deep', 'learning', 'machine', 'learning', 'strong', 'ability', 'learn', 'technology', 'framework', 'fast', 'solid', 'knowledge', 'xgboost', 'gurobi', 'algorithms', 'deep', 'learning', 'machine', 'learning', 'ability', 'read', 'implement', 'scientific', 'articles', 'ai', 'experience', 'different', 'database', 'management', 'systems', 'mongodb', 'mysql', 'graphdb', 'experience', 'working', 'python', 'servers', 'flask', 'tornado', 'knowledge', 'common', 'frameworks', 'opencv', 'caffe', 'tensor', 'flow', 'etc', 'ability', 'read', 'understand', 'english', 'technical', 'documents', 'senior', 'leader', 'role', 'expect', 'strong', 'knowledge', 'dl', 'ml', 'experience', 'ai', 'development', 'least', '3', '+', 'years', 'experience', 'implementing', 'deep', 'learning', 'machine', 'learning', 'models', 'proficient', 'python', 'good', 'knowledge', 'ml', 'dl', 'proficient', 'using', 'opencv', 'tensorflow', 'pytorch', 'ability', 'research', 'explore', 'technology', 'good', 'algorithmic', 'thinking', 'da', 'nang', 'office', '9f', '81', 'quang', 'trung', 'st', 'hai', 'chau', 'dist', 'da', 'nang', 'city', 'vietnam', 'hcm', 'office', 'viettel', 'complex', 'building', '285', 'cmt', '8', 'st', 'w12', 'd10', 'hcm', 'city', 'vietnam', '0286', '2701', '557', 'https://bap-software.net/en/', 'bap', 'software', 'co', 'ltd', '10f', '81', 'quang', 'trung', 'st', 'hai', 'chau', 'dist', 'da', 'nang', 'city', 'vietnam', 'website', 'https://bap-software.net/en/', 'ability', 'orient', 'technology', 'research', 'orientation', 'team', 'ability', 'review', 'code', 'python', 'team', 'member', 'ability', 'manage', 'work', 'manage', 'team', 'ability', 'read', 'understand', 'english', 'technical', 'documents', 'ability', 'work', 'pressure', 'startup', 'environment', 'successful', 'product', 'launch', 'practical', 'work', 'experience', 'advance', 'location', 'da', 'nang', 'offer', 'opportunity', 'develop', 'engineer', 'ai', 'field', 'competitive', 'salary', '13th', 'month', 'salary', '12day', 'annual', 'leave', 'full', 'insurance', 'package', 'holidays', 'bonus', 'performance', 'reward', 'program', 'salaries', 'performance', 'review', '2', 'times', 'per', 'year', 'promotion', 'opportunity', 'monthly', 'team-building', 'funds', 'english', 'japanese', 'skills', 'certificate', 'incentive', 'bonus', 'program', 'japanese', 'onsite', 'opportunity', 'gifts', 'family', 'tet', 'childrens', 'day', 'mid-autumn', 'festival', 'diverse', 'company', 'culture', 'activities', 'company', 'trip', 'division', 'picnics', 'christmas', 'night', 'year', 'end', 'party', 'womens', 'day', 'mens', 'day', 'international', 'environment', 'colleagues', 'different', 'countries', 'vietnam', 'japan', 'australia', 'singapore', 'etc', 'apply', 'drop', 'cv', 'email', 'contact', 'us', 'information', 'via', 'email', 'recruit@bap-solutions.com', 'skype', 'nhungnn.hip', 'hope', 'meet', 'soon', 'bap', 'cheers', 'da', 'nang', 'office', '9f', '81', 'quang', 'trung', 'st', 'hai', 'chau', 'dist', 'da', 'nang', 'city', 'vietnam', 'hcm', 'office', 'viettel', 'complex', 'building', '285', 'cmt', '8', 'st', 'w12', 'd10', 'hcm', 'city', 'vietnam', '0286', '2701', '557', 'https://bap-software.net/en/']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "#to find the vector of a new input document\n",
    "clean_jd = \"D://pythonProject/Internship/Resume Screening/data/preprocessed_txt_JD/[BAP SOFTWARE] AI ENGINEER.txt\"\n",
    "file_jd = open(str(clean_jd), 'r')\n",
    "test_data_jd = file_jd.read()\n",
    "test_data_jd = test_data_jd.split()\n",
    "print(test_data_jd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c81d4db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "projectDir = 'D://pythonProject/Internship/Resume Screening/data/'\n",
    "clean_jd_dir = projectDir+'new_preprocessed_txt_JD/'\n",
    "all_jd = []\n",
    "all_jd_name = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9767819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(clean_jd_dir)\n",
    "for clean_jd in os.listdir(clean_jd_dir):\n",
    "    file = open(str(clean_jd), 'r')\n",
    "    all_jd_name.append(str(clean_jd))\n",
    "    jd = file.read()\n",
    "    all_jd.append(jd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d59389c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "jd = []\n",
    "for i in range(len(all_jd)):\n",
    "    test_data_jd = all_jd[i].split()\n",
    "    jd.append(model_jd.infer_vector(test_data_jd))\n",
    "    jd[i] = jd[i].reshape(1, -1)\n",
    "print(len(jd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bb8bbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['php', 'php', 'php', 'php', 'php', 'phpmyadmin', 'mysql', 'php', 'mysql', 'mvc', 'laravel', 'framework', 'php', 'html', 'css', 'javascript', 'bootstrap', 'framework', 'laravel', 'mysql', 'php', 'mysql', 'laravel', 'framework', 'jquery', 'javascript', 'mysql', 'laravel', 'framework', 'html', 'css', 'bootstrap', 'php', 'mysql', 'php', 'combine', 'html', 'css', 'javascript']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "#to find the vector of a new input document\n",
    "clean_cv = \"D://pythonProject/Internship/Resume Screening/data/new_preprocessed_txt_data/PHP/[Fresher] Bùi Hoàng Nhật - PHP.txt\"\n",
    "file_cv = open(str(clean_cv), 'r')\n",
    "test_data_cv = file_cv.read()\n",
    "test_data_cv = test_data_cv.split()\n",
    "print(test_data_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa711626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector_cv_infer [[ 7.22881973e-01  8.37660015e-01 -5.23583516e-02 -1.28047180e+00\n",
      "   4.35626179e-01  1.31364095e+00 -3.17696214e-01  6.43825591e-01\n",
      "  -1.17543709e+00 -2.32136726e+00  1.35484233e-01 -7.66554415e-01\n",
      "  -1.04958504e-01  2.31264487e-01  4.10977975e-02 -5.02311766e-01\n",
      "   1.46337199e+00 -4.34674203e-01 -6.02834940e-01 -1.72340834e+00\n",
      "  -1.12955141e+00 -3.36462975e-01  1.39101827e+00 -8.40078831e-01\n",
      "  -7.57857203e-01 -8.04691434e-01  3.95499498e-01 -1.18264413e+00\n",
      "  -5.79580143e-02  1.60710573e+00  3.15536976e-01 -2.04773974e+00\n",
      "  -5.39182603e-01 -2.99074292e-01 -7.84700572e-01  2.09842682e+00\n",
      "   7.29529858e-01  5.70261836e-01 -7.88897455e-01 -1.16113520e+00\n",
      "   1.67042720e+00 -1.29253909e-01  7.89426029e-01 -3.24161440e-01\n",
      "   9.05549765e-01 -8.67883027e-01  4.29419279e-01 -1.38015842e+00\n",
      "  -8.86242390e-02  1.32013214e+00 -6.22016899e-02 -1.66017354e+00\n",
      "   1.44575179e-01  5.17203748e-01 -3.32041264e+00 -2.57095963e-01\n",
      "   9.78890300e-01 -1.34282720e+00 -7.98778832e-01 -1.29916537e+00\n",
      "   9.54347432e-01  6.98468268e-01  2.46303487e+00 -4.86792892e-01\n",
      "  -2.31920704e-02  1.37685752e+00 -5.37743926e-01 -2.17905283e-01\n",
      "  -1.10069036e+00 -3.60089332e-01  1.54243803e+00  2.88247752e+00\n",
      "  -1.64131587e-03  9.35913444e-01  1.02792621e+00  2.16981187e-01\n",
      "   6.79234639e-02  8.72202098e-01  8.96658540e-01  3.67339045e-01\n",
      "  -4.20044273e-01 -9.32025969e-01  4.13328499e-01 -1.19924366e+00\n",
      "  -5.92192829e-01 -7.65508235e-01 -1.77569523e-01 -3.38992983e-01\n",
      "  -1.58527911e-01  1.07517183e+00 -9.97425079e-01  1.21182692e+00\n",
      "  -1.40056893e-01 -9.49688017e-01  2.53871059e+00 -8.76995683e-01\n",
      "   1.12563980e+00 -7.04759419e-01  8.15916359e-01 -7.15759158e-01]]\n"
     ]
    }
   ],
   "source": [
    "resume = model_resume.infer_vector(test_data_cv)\n",
    "resume = resume.reshape(1, -1)\n",
    "print(\"Vector_cv_infer\", resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5ba316",
   "metadata": {},
   "source": [
    "# Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fe78d390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BAP SOFTWARE] NODEJS DEV.txt: 0.36 nodejs nodejs nodejs expressjs restful api mysql postgresql mongodb firebase reactjs angular vuejs docker\n",
      "[BAP SOFTWARE] FRONTEND DEV.txt: 0.32 reactjs vuejs vuejs html css javascript reactjs ux reactjs vuejs html css javascript es5 framework sass angular nodejs mongodb mysql ux restful api\n",
      "[BAP SOFTWARE] WEB_ APP DESIGNER.txt: 0.31 ux ux ux\n",
      "[BAP SOFTWARE] C# DEV.txt: 0.27 winform framework mysql restful api docker cd\n",
      "[BAP SOFTWARE] FULLSTACK DEV.txt: 0.27 nodejs php mongodb reactjs javascript reactjs nodejs php html css es5 expressjs laravel restful api mysql postgresql mongodb mvc firebase php angular vuejs cd docker\n",
      "[BAP IT] BRSE.txt: 0.26 php\n",
      "[BAP SOFTWARE] FULLSTACK JS DEV.txt: 0.25 javascript javascript javascript node.js react javascript ux gitlab nodejs react nodejs javascript reactjs html css javascript restful cd javascript\n",
      "[BAP SOFTWARE] IT COMTOR.txt: 0.24 framework\n",
      "[BAP SOFTWARE] QC_ TESTER.txt: 0.24 mysql api\n",
      "[BAP SOFTWARE] SOFTWARE ARCHITECT.txt: 0.23 reactjs framework microservice cd\n",
      "[BAP IT] IT INFRA ENGINEER.txt: 0.22 postgresql mysql mongodb cloudformation docker container\n",
      "[BAP SOFTWARE] INTERN _ FRESHER 2021.txt: 0.22 blockchain php nodejs reactjs php nodejs reactjs chance blockchain php nodejs reactjs blockchain deep php javascript blockchain php nodejs reactjs blockchain\n",
      "[BAP SOFTWARE] TECHNICAL LEADER.txt: 0.22 framework microservice cd\n",
      "[BAP IT] DEVOPS ENGINEER.txt: 0.21 postgresql mysql mongodb docker container\n",
      "[BAP SOFTWARE] PROJECT MANAGER.txt: 0.21 nodejs php javascript entrepreneurial\n",
      "[BAP SOFTWARE] SENIOR PROJECT MANAGER.txt: 0.21 nodejs php javascript entrepreneurial\n",
      "[BAP SOFTWARE] PHP DEV.txt: 0.2 php php php php laravel framework mvc php framework laravel cakephp mysql mongodb restful api nodejs reactjs vuejs cd docker\n",
      "[BAP SOFTWARE] PYTHON DEVELOPER.txt: 0.2 framework framework postgresql react docker\n",
      "[BAP VENTURES] FRESHER BLOCKCHAIN.txt: 0.17 blockchain blockchain blockchain chance blockchain\n",
      "[BAP SOFTWARE] AI ENGINEER (INTERN_ FRESHER).txt: 0.16 deep deep deep deep cnn tensor\n",
      "[BAP SOFTWARE] AI ENGINEER.txt: 0.14 deep deep framework deep mongodb mysql tensor deep pytorch\n",
      "[BAP SOFTWARE] BLOCKCHAIN DEVELOPER.txt: 0.14 blockchain blockchain blockchain blockchain blockchain blockchain nodejs docker framework\n",
      "[BAP SOFTWARE] PROJECT LEADER.txt: 0.14 node js php\n",
      "[BAP SOFTWARE] SENIOR PYTHON.txt: 0.14 framework framework postgresql js docker\n",
      "[BAP SOFTWARE] C_B SPECIALIST.txt: 0.13 periodically periodically\n",
      "[BAP SOFTWARE] OUTSYSTEM DEV.txt: 0.11 html css javascript mvc cd\n",
      "[BAP SOFTWARE] INTERN BLOCKCHAIN_.txt: 0.1 blockchain blockchain blockchain blockchain blockchain blockchain deep blockchain blockchain nodejs blockchain blockchain blockchain\n",
      "[BAP SOFTWARE] JAVA DEV.txt: 0.1 jsp thymeleaf struts spring spring boot mvc hibernate jax-rs gradle mybatis json restful api docker cd javascript framework angularjs react nodejs\n",
      "[BAP SOFTWARE] PART TIME- ADMIN OFFICER.txt: 0.09\n",
      "[BAP SOFTWARE] SENIOR JAVA.txt: 0.07 spring boot spring mvc restful api spring jpa j2ee jpa hibernate jax-rs json cd docker javascript framework angularjs react nodejs\n",
      "[BAP SOFTWARE] ANDROID DEV.txt: 0.05 mvc json react flutter\n",
      "[BAP SOFTWARE] ADMINISTRATIVE OFFICER.txt: 0.03\n",
      "[BAP SOFTWARE] JAVA IN DA NANG.txt: 0.03 spring boot spring mvc restful api spring jpa j2ee jpa hibernate jax-rs json javascript framework angularjs react nodejs\n",
      "[BAP SOFTWARE] ROR DEV.txt: 0.01 ruby rails ruby rails ruby ruby rails framework restful api mysql postgresql mongodb mvc html javascript css nodejs reactjs vuejs docker jquery\n",
      "[BAP SOFTWARE] SALESFORCE DEVELOPER.txt: -0.03\n",
      "[BAP SOFTWARE] SALES ASSISTANT.txt: -0.04\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# get the match percentage\n",
    "matchPercentage = []\n",
    "for i in range(len(jd)):\n",
    "    matchPercentage.append(cosine_similarity(jd[i], resume)[0][0])\n",
    "    matchPercentage[i] = round(matchPercentage[i], 2) # round to two decimal\n",
    "    \n",
    "index = [i for i, j in enumerate(matchPercentage)]\n",
    "value = [j for i, j in enumerate(matchPercentage)]\n",
    "top_match = sorted(zip(index, value), reverse=True, key=lambda x: x[1])[:]\n",
    "\n",
    "\n",
    "for i in range(len(top_match)):\n",
    "    print(all_jd_name[top_match[i][0]] + \": \" + str(top_match[i][1]) + all_jd[top_match[i][0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec15632",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Internship",
   "language": "python",
   "name": "internship"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
